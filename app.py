from flask import Flask, render_template, request, jsonify, session, redirect, url_for
import os
from datetime import datetime
import uuid
import json

# Importar el agente de LangGraph
from agentes import procesar_conjetura
from agentes.formal_causal_agent import (
    get_llm, safe_llm_call,
    PROMPT_PRECEPTIVAS, PROMPT_TECNICAS, 
    PROMPT_FACULTATIVAS, PROMPT_PROGRESISTAS,
    PROMPT_OBJETIVOS, PROMPT_QUE_ES
)

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'

# Almacenamiento temporal de informes (en producci√≥n usar base de datos)
informes_generados = {}

@app.route('/')
def index():
    """Renderiza la p√°gina principal"""
    return render_template('index.html')

@app.route('/iniciar-informe', methods=['POST'])
def iniciar_informe():
    """
    Endpoint para iniciar un nuevo informe guardando la conjetura.
    Redirige a la p√°gina de revisi√≥n donde se procesar√° con el agente.
    """
    data = request.get_json()
    conjetura = data.get('conjetura', '')
    
    if not conjetura or len(conjetura.strip()) < 10:
        return jsonify({
            'success': False,
            'message': 'La conjetura debe tener al menos 10 caracteres.'
        }), 400
    
    # Generar ID √∫nico para el informe
    informe_id = str(uuid.uuid4())
    
    print(f"\n{'='*60}")
    print(f"üöÄ NUEVO INFORME INICIADO - ID: {informe_id[:8]}...")
    print(f"{'='*60}")
    print(f"Conjetura: {conjetura[:100]}...")
    
    # Guardar solo la conjetura inicialmente
    informes_generados[informe_id] = {
        'conjetura': conjetura,
        'analisis': None,
        'informe_generado': False
    }
    
    return jsonify({
        'success': True,
        'message': 'Redirigiendo a revisi√≥n...',
        'informe_id': informe_id,
        'redirect_url': f'/revisar-motivaciones/{informe_id}'
    })

@app.route('/procesar-con-agente/<informe_id>', methods=['POST'])
def procesar_con_agente(informe_id):
    """
    Endpoint para iniciar el procesamiento as√≠ncrono con el agente de IA.
    """
    if informe_id not in informes_generados:
        return jsonify({
            'success': False,
            'message': 'Informe no encontrado'
        }), 404
    
    print(f"\n{'='*60}")
    print(f"üöÄ INICIANDO AN√ÅLISIS DEL M√âTODO FORMAL CAUSAL")
    print(f"{'='*60}\n")
    
    # Inicializar estructura de an√°lisis vac√≠a si no existe
    if not informes_generados[informe_id].get('analisis'):
        informes_generados[informe_id]['analisis'] = {
            'por_que': {
                'preceptivas': [],
                'tecnicas': [],
                'facultativas': [],
                'progresistas': []
            },
            'para_que': [],
            'que_es': {}
        }
    
    return jsonify({
        'success': True,
        'message': 'Procesamiento iniciado'
    })

@app.route('/obtener-paquete/<informe_id>/<paquete>', methods=['GET'])
def obtener_paquete(informe_id, paquete):
    """
    Endpoint para obtener un paquete espec√≠fico de motivaciones.
    Procesa el paquete si a√∫n no est√° generado.
    """
    if informe_id not in informes_generados:
        return jsonify({
            'success': False,
            'message': 'Informe no encontrado'
        }), 404
    
    try:
        conjetura = informes_generados[informe_id]['conjetura']
        analisis = informes_generados[informe_id]['analisis']
        
        print(f"DEBUG: Solicitado paquete='{paquete}', tipo={type(paquete)}")
        
        # Diccionario de prompts (fuera del if para evitar scope issues)
        prompts_motivaciones = {
            'preceptivas': PROMPT_PRECEPTIVAS,
            'tecnicas': PROMPT_TECNICAS,
            'facultativas': PROMPT_FACULTATIVAS,
            'progresistas': PROMPT_PROGRESISTAS
        }
        
        print(f"DEBUG: Claves disponibles en prompts_motivaciones: {list(prompts_motivaciones.keys())}")
        
        # Verificar si el paquete ya fue generado
        if paquete in prompts_motivaciones:
            if analisis['por_que'][paquete]:
                print(f"üì¶ Paquete '{paquete}' ya generado (cache)")
                return jsonify({
                    'success': True,
                    'paquete': paquete,
                    'motivaciones': analisis['por_que'][paquete],
                    'cached': True
                })
            
            # Generar el paquete espec√≠fico
            print(f"üîç Analizando motivaciones {paquete.upper()}...")
            
            llm = get_llm()
            prompt_template = prompts_motivaciones[paquete]
            
            # Formatear el prompt seg√∫n el paquete
            print(f"DEBUG: Formateando prompt para paquete='{paquete}'")
            if paquete == 'preceptivas':
                print(f"DEBUG: Caso preceptivas")
                prompt = prompt_template.format(conjetura=conjetura)
            elif paquete == 'tecnicas':
                print(f"DEBUG: Caso tecnicas")
                preceptivas_str = json.dumps(analisis['por_que']['preceptivas'], indent=2, ensure_ascii=False)
                prompt = prompt_template.format(conjetura=conjetura, preceptivas=preceptivas_str)
            elif paquete == 'facultativas':
                preceptivas_str = json.dumps(analisis['por_que']['preceptivas'], indent=2, ensure_ascii=False)
                tecnicas_str = json.dumps(analisis['por_que']['tecnicas'], indent=2, ensure_ascii=False)
                prompt = prompt_template.format(conjetura=conjetura, preceptivas=preceptivas_str, tecnicas=tecnicas_str)
            elif paquete == 'progresistas':
                preceptivas_str = json.dumps(analisis['por_que']['preceptivas'], indent=2, ensure_ascii=False)
                tecnicas_str = json.dumps(analisis['por_que']['tecnicas'], indent=2, ensure_ascii=False)
                facultativas_str = json.dumps(analisis['por_que']['facultativas'], indent=2, ensure_ascii=False)
                prompt = prompt_template.format(
                    conjetura=conjetura,
                    preceptivas=preceptivas_str,
                    tecnicas=tecnicas_str,
                    facultativas=facultativas_str
                )
            
            # Crear un default espec√≠fico para este paquete
            result = safe_llm_call(llm, prompt, None)
            
            # Si el resultado es None o no es dict, usar array vac√≠o
            if result is None or not isinstance(result, dict):
                print(f"‚ö†Ô∏è LLM no devolvi√≥ resultado v√°lido para {paquete}")
                motivaciones = []
            elif paquete in result:
                motivaciones = result[paquete]
            else:
                print(f"‚ö†Ô∏è La clave '{paquete}' no est√° en el resultado del LLM. Claves disponibles: {list(result.keys())}")
                motivaciones = []
            
            # Guardar en memoria
            analisis['por_que'][paquete] = motivaciones
            
            num_motivaciones = len(motivaciones)
            print(f"‚úÖ Encontradas {num_motivaciones} motivaciones {paquete}")
            
            return jsonify({
                'success': True,
                'paquete': paquete,
                'motivaciones': motivaciones,
                'cached': False
            })
            
        elif paquete == 'objetivos':
            if analisis['para_que']:
                print(f"üì¶ Objetivos ya generados (cache)")
                return jsonify({
                    'success': True,
                    'paquete': 'objetivos',
                    'objetivos': analisis['para_que'],
                    'cached': True
                })
            
            # Generar objetivos
            print(f"üîç Analizando OBJETIVOS (¬øPara qu√©?)...")
            
            llm = get_llm()
            preceptivas_str = json.dumps(analisis['por_que']['preceptivas'], indent=2, ensure_ascii=False)
            tecnicas_str = json.dumps(analisis['por_que']['tecnicas'], indent=2, ensure_ascii=False)
            facultativas_str = json.dumps(analisis['por_que']['facultativas'], indent=2, ensure_ascii=False)
            progresistas_str = json.dumps(analisis['por_que']['progresistas'], indent=2, ensure_ascii=False)
            
            prompt = PROMPT_OBJETIVOS.format(
                conjetura=conjetura,
                preceptivas=preceptivas_str,
                tecnicas=tecnicas_str,
                facultativas=facultativas_str,
                progresistas=progresistas_str
            )
            
            result = safe_llm_call(llm, prompt, {"para_que": []})
            objetivos = result.get('para_que', [])
            analisis['para_que'] = objetivos
            
            num_objetivos = len(objetivos)
            print(f"‚úÖ Encontrados {num_objetivos} objetivos")
            
            return jsonify({
                'success': True,
                'paquete': 'objetivos',
                'objetivos': objetivos,
                'cached': False
            })
            
        elif paquete == 'que_es':
            if analisis['que_es']:
                print(f"üì¶ Definici√≥n 'Qu√© es' ya generada (cache)")
                return jsonify({
                    'success': True,
                    'paquete': 'que_es',
                    'definicion': analisis['que_es'],
                    'cached': True
                })
            
            # Generar qu√© es
            print(f"üîç Definiendo QU√â ES el problema...")
            
            llm = get_llm()
            preceptivas_str = json.dumps(analisis['por_que']['preceptivas'], indent=2, ensure_ascii=False)
            tecnicas_str = json.dumps(analisis['por_que']['tecnicas'], indent=2, ensure_ascii=False)
            facultativas_str = json.dumps(analisis['por_que']['facultativas'], indent=2, ensure_ascii=False)
            progresistas_str = json.dumps(analisis['por_que']['progresistas'], indent=2, ensure_ascii=False)
            objetivos_str = json.dumps(analisis['para_que'], indent=2, ensure_ascii=False)
            
            prompt = PROMPT_QUE_ES.format(
                conjetura=conjetura,
                preceptivas=preceptivas_str,
                tecnicas=tecnicas_str,
                facultativas=facultativas_str,
                progresistas=progresistas_str,
                objetivos=objetivos_str
            )
            
            result = safe_llm_call(llm, prompt, {"que_es": {}})
            definicion = result.get('que_es', {})
            analisis['que_es'] = definicion
            
            print(f"‚úÖ Definici√≥n completada")
            
            return jsonify({
                'success': True,
                'paquete': 'que_es',
                'definicion': definicion,
                'cached': False
            })
        
        return jsonify({
            'success': False,
            'message': 'Paquete no reconocido'
        }), 400
        
    except Exception as e:
        print(f"‚ùå Error al obtener paquete {paquete}: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'Error: {str(e)}'
        }), 500

@app.route('/revisar-motivaciones/<informe_id>')
def revisar_motivaciones(informe_id):
    """P√°gina para revisar y editar motivaciones antes de generar el informe"""
    if informe_id not in informes_generados:
        return redirect(url_for('index'))
    
    data = informes_generados[informe_id]
    return render_template('revisar_motivaciones.html', 
                         informe_id=informe_id,
                         conjetura=data['conjetura'],
                         analisis_data=data.get('analisis'))

@app.route('/guardar-motivacion', methods=['POST'])
def guardar_motivacion():
    """Guardar una motivaci√≥n editada"""
    data = request.get_json()
    informe_id = data.get('informe_id')
    paquete = data.get('paquete')
    indice = data.get('indice')
    motivacion = data.get('motivacion')
    
    if informe_id not in informes_generados:
        return jsonify({
            'success': False,
            'message': 'Informe no encontrado'
        }), 404
    
    try:
        # Actualizar la motivaci√≥n en memoria
        analisis = informes_generados[informe_id]['analisis']
        analisis['por_que'][paquete][indice] = motivacion
        
        print(f"üíæ Motivaci√≥n guardada: {paquete}[{indice}] - {motivacion['titulo'][:50]}")
        
        return jsonify({
            'success': True,
            'message': 'Motivaci√≥n guardada correctamente'
        })
    except Exception as e:
        print(f"‚ùå Error al guardar motivaci√≥n: {e}")
        return jsonify({
            'success': False,
            'message': f'Error al guardar: {str(e)}'
        }), 500

@app.route('/generar-informe-final', methods=['POST'])
def generar_informe_final():
    """Generar el informe final despu√©s de revisar las motivaciones"""
    data = request.get_json()
    informe_id = data.get('informe_id')
    
    if informe_id not in informes_generados:
        return jsonify({
            'success': False,
            'message': 'Informe no encontrado'
        }), 404
    
    try:
        datos = informes_generados[informe_id]
        
        print(f"\n{'='*60}")
        print(f"üìÑ GENERANDO INFORME FINAL")
        print(f"{'='*60}\n")
        
        # Generar el informe completo con las motivaciones revisadas
        informe_data = generar_informe_con_ia(datos['conjetura'], datos['analisis'])
        
        # Reemplazar los datos con el informe completo
        informes_generados[informe_id] = informe_data
        informes_generados[informe_id]['informe_generado'] = True
        
        print(f"‚úÖ Informe generado correctamente\n")
        
        return jsonify({
            'success': True,
            'message': 'Informe generado correctamente'
        })
    except Exception as e:
        print(f"‚ùå Error al generar informe final: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'Error al generar informe: {str(e)}'
        }), 500

@app.route('/informe/<informe_id>')
def ver_informe(informe_id):
    """Mostrar el informe generado"""
    if informe_id not in informes_generados:
        return redirect(url_for('index'))
    
    informe_data = informes_generados[informe_id]
    
    # Si el informe no ha sido generado a√∫n, redirigir a revisi√≥n
    if not informe_data.get('informe_generado', True):
        return redirect(url_for('revisar_motivaciones', informe_id=informe_id))
    
    return render_template('informe.html', informe=informe_data, informe_id=informe_id)

@app.route('/mapa-conceptual/<informe_id>')
def ver_mapa_conceptual(informe_id):
    """Mostrar el mapa conceptual del informe"""
    if informe_id not in informes_generados:
        return redirect(url_for('index'))
    
    informe_data = informes_generados[informe_id]
    return render_template('mapa_conceptual_v2.html', informe=informe_data, informe_id=informe_id)

@app.route('/metodo-formal-causal')
def metodo_info():
    """Informaci√≥n sobre el m√©todo formal causal"""
    metodo = {
        'nombre': 'M√©todo Formal Causal',
        'fases': [
            {
                'pregunta': '¬øPor qu√©?',
                'tipos': [
                    {'nombre': 'Preceptivas', 'descripcion': 'Surgen del propio enunciado del problema'},
                    {'nombre': 'T√©cnicas', 'descripcion': 'Impl√≠citas en el problema (leyes, normas, etc.)'},
                    {'nombre': 'Facultativas', 'descripcion': 'Motivan al autor a resolver el problema'},
                    {'nombre': 'Progresistas', 'descripcion': 'Aportaci√≥n al conocimiento actual'}
                ]
            },
            {
                'pregunta': '¬øPara qu√©?',
                'descripcion': 'Se relacionan con sus respectivos por qu√©'
            },
            {
                'pregunta': '¬øQu√© es?',
                'descripcion': 'Definici√≥n y contextualizaci√≥n del problema'
            }
        ]
    }
    return jsonify(metodo)

def generar_informe_con_ia(conjetura: str, analisis: dict):
    """
    Genera un informe completo usando el an√°lisis del agente de IA
    
    Args:
        conjetura: Texto de la conjetura inicial
        analisis: Diccionario con el an√°lisis generado por el agente (por_que, para_que, que_es)
    """
    fecha_actual = datetime.now().strftime('%d de %B de %Y')
    
    return {
        'numero_expediente': f'EXP-{datetime.now().strftime("%Y%m%d")}-{uuid.uuid4().hex[:6].upper()}',
        'fecha_elaboracion': fecha_actual,
        'conjetura': conjetura,
        
        'perito': {
            'nombre': 'Dr./Dra. [NOMBRE DEL PERITO]',
            'dni': '[DNI/NIE]',
            'direccion': '[Direcci√≥n profesional completa]',
            'telefono': '[Tel√©fono de contacto]',
            'email': '[email@ejemplo.com]',
            'titulo': '[T√≠tulo profesional]',
            'especialidad': '[Especialidad del perito]',
            'num_colegiado': '[N√∫mero de colegiado]',
            'experiencia': 'El perito cuenta con [X] a√±os de experiencia en el √°mbito de [especialidad], habiendo realizado numerosos informes periciales en casos similares. [A√±adir m√°s detalles relevantes sobre la experiencia].',
            'juramento': 'Juro o prometo, por mi conciencia y honor, que ejercer√© fielmente el cargo de perito, desempe√±ando mis funciones con imparcialidad y objetividad, cumpliendo con los deberes inherentes al mismo.'
        },
        
        'solicitante': {
            'nombre': '[Nombre del solicitante / Juzgado]',
            'representacion': '[Abogado/Procurador o tipo de representaci√≥n]',
            'domicilio': '[Domicilio del solicitante]',
            'tipo_encargo': '[Judicial / Extrajudicial / Particular]'
        },
        
        'descripcion': {
            'hecho': f'El presente informe pericial tiene por objeto analizar y determinar los aspectos t√©cnicos relacionados con la siguiente conjetura: "{conjetura}". Se proceder√° a realizar un an√°lisis exhaustivo aplicando el M√©todo Formal Causal para garantizar la fundamentaci√≥n de las conclusiones.',
            'fecha_lugar': '[Fecha y lugar del suceso si aplica]',
            'alcance': 'El alcance del presente informe pericial comprende el an√°lisis t√©cnico y cient√≠fico de todos los aspectos relevantes relacionados con la conjetura planteada, aplicando la metodolog√≠a del M√©todo Formal Causal para establecer las motivaciones (preceptivas, t√©cnicas, facultativas y progresistas), los objetivos (para qu√©) y la definici√≥n precisa del problema (qu√© es).'
        },
        
        'antecedentes': {
            'hechos_previos': 'Con car√°cter previo al presente an√°lisis, se han identificado los siguientes hechos relevantes que constituyen el contexto de la pericia. Se establecen a continuaci√≥n los antecedentes f√°cticos que resultan de aplicaci√≥n al caso objeto de estudio.',
            'documentacion': [
                'Documentaci√≥n aportada por el solicitante',
                'Normativa t√©cnica aplicable',
                'Informes previos (si los hubiere)',
                'Fotograf√≠as y material gr√°fico',
                'Otra documentaci√≥n relevante'
            ],
            'normativa': 'Normativa legal y t√©cnica aplicable al caso seg√∫n el an√°lisis realizado y el √°mbito de aplicaci√≥n correspondiente.'
        },
        
        'metodologia': {
            'tecnicas': [
                'Aplicaci√≥n del M√©todo Formal Causal',
                'An√°lisis documental exhaustivo',
                'Inspecci√≥n t√©cnica (si procede)',
                'An√°lisis normativo aplicable',
                'Consulta de fuentes t√©cnicas y cient√≠ficas especializadas'
            ],
            'criterios': 'Los criterios de valoraci√≥n empleados se basan en principios de objetividad, imparcialidad y rigor cient√≠fico-t√©cnico, aplicando las mejores pr√°cticas profesionales del sector y la normativa vigente aplicable al caso.',
            'normas': 'Normas t√©cnicas, legales y reglamentarias espec√≠ficas aplicadas en el an√°lisis seg√∫n corresponda.',
            'herramientas': [
                'Sistema de Informes Periciales',
                'Software de an√°lisis t√©cnico especializado',
                'Bases de datos jur√≠dicas y t√©cnicas',
                'Herramientas de medici√≥n y c√°lculo (si aplica)'
            ]
        },
        
        'analisis': {
            'por_que': analisis['por_que'],  # Datos generados por la IA
            'para_que': analisis['para_que'],  # Datos generados por la IA
            'que_es': analisis['que_es'],  # Datos generados por la IA
            'inspecciones': 'Descripci√≥n detallada de las inspecciones realizadas, metodolog√≠a empleada, condiciones de la inspecci√≥n y observaciones relevantes.',
            'resultados': 'Presentaci√≥n de resultados t√©cnicos, c√°lculos realizados, mediciones obtenidas y datos cuantitativos relevantes para el an√°lisis.',
            'evaluacion': 'Evaluaci√≥n objetiva de los resultados obtenidos, contrast√°ndolos con los est√°ndares t√©cnicos aplicables y la normativa vigente.'
        },
        
        'conclusiones': {
            'respuestas': [
                'Primera conclusi√≥n t√©cnica fundamentada en el an√°lisis realizado.',
                'Segunda conclusi√≥n t√©cnica fundamentada en los resultados obtenidos.',
                'Tercera conclusi√≥n t√©cnica basada en la evaluaci√≥n de los elementos probatorios.',
                'Conclusiones adicionales seg√∫n el desarrollo del an√°lisis pericial.'
            ],
            'opinion_tecnica': 'Opini√≥n t√©cnica profesional del perito sobre el caso analizado, fundamentada en el an√°lisis realizado y en su experiencia profesional, estableciendo de forma clara y precisa su valoraci√≥n t√©cnica del caso.',
            'recomendaciones': [
                'Recomendaci√≥n t√©cnica basada en las conclusiones del an√°lisis.',
                'Recomendaci√≥n profesional derivada de los hallazgos del informe.'
            ]
        },
        
        'anexos': [
            'Documentaci√≥n fotogr√°fica',
            'Planos y esquemas t√©cnicos',
            'C√°lculos y tablas detalladas',
            'Normativa aplicable (textos completos)',
            'Otra documentaci√≥n de referencia'
        ],
        
        'firma': {
            'lugar': '[Ciudad]',
            'fecha': fecha_actual
        }
    }


def generar_informe_demo(conjetura):
    """
    Genera datos de demostraci√≥n para el informe (BACKUP)
    Esta funci√≥n se mantiene como respaldo en caso de que falle la IA
    """
    fecha_actual = datetime.now().strftime('%d de %B de %Y')
    
    # An√°lisis b√°sico de respaldo
    analisis_demo = {
        'por_que': {
            'preceptivas': [
                {
                    'titulo': 'An√°lisis del enunciado del problema',
                    'contenido': 'Estudio detallado de los elementos esenciales del problema tal como ha sido formulado.'
                }
            ],
            'tecnicas': [
                {
                    'titulo': 'Marco normativo aplicable',
                    'contenido': 'Identificaci√≥n de leyes, normas t√©cnicas y est√°ndares profesionales aplicables.'
                }
            ],
            'facultativas': [
                {
                    'titulo': 'Inter√©s profesional en el caso',
                    'contenido': 'Motivaci√≥n del perito para aplicar conocimientos especializados.'
                }
            ],
            'progresistas': [
                {
                    'titulo': 'Aportaci√≥n al conocimiento t√©cnico',
                    'contenido': 'Identificaci√≥n de aspectos novedosos del caso.'
                }
            ]
        },
        'para_que': [
            {
                'titulo': 'Establecer la verdad t√©cnica de los hechos',
                'tipo': 'preceptivas',
                'contenido': 'Determinar con precisi√≥n la naturaleza de los hechos.'
            }
        ],
        'que_es': {
            'contenido': 'Definici√≥n precisa del problema objeto de an√°lisis.',
            'contexto': 'Contextualizaci√≥n del problema dentro del marco t√©cnico aplicable.'
        }
    }
    
    return generar_informe_con_ia(conjetura, analisis_demo)


if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
